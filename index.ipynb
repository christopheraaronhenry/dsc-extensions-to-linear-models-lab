{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extensions to Linear Models - Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this lab, you'll practice many concepts you have learned so far, from adding interactions and polynomials to your model to regularization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Build a linear regression model with interactions and polynomial features \n",
    "- Use feature selection to obtain the optimal subset of features in a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started!\n",
    "\n",
    "Below we import all the necessary packages for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from itertools import combinations\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "\n",
    "# Load data from CSV\n",
    "df = pd.read_csv(\"ames.csv\")\n",
    "# Subset columns\n",
    "df = df[['LotArea', 'OverallQual', 'OverallCond', 'TotalBsmtSF',\n",
    "         '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'TotRmsAbvGrd',\n",
    "         'GarageArea', 'Fireplaces', 'SalePrice']]\n",
    "\n",
    "# Split the data into X and y\n",
    "y = df['SalePrice']\n",
    "X = df.drop(columns='SalePrice')\n",
    "\n",
    "# Split into train, test, and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Baseline Housing Data Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we imported the Ames housing data and grabbed a subset of the data to use in this analysis.\n",
    "\n",
    "Next steps:\n",
    "\n",
    "- Scale all the predictors using `StandardScaler`, then convert these scaled features back into DataFrame objects\n",
    "- Build a baseline `LinearRegression` model using *scaled variables* as predictors and use the $R^2$ score to evaluate the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "# Scale X_train and X_test using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "# Ensure X_train and X_test are scaled DataFrames\n",
    "# (hint: you can set the columns using X.columns)\n",
    "X_train = pd.DataFrame(X_train_transformed, columns = X_train.columns, index=X_train.index)\n",
    "X_test = pd.DataFrame(X_test_transformed, columns = X_test.columns, index=X_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline r_sqaured on training data:  0.7868344817421309\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Create a LinearRegression model and fit it on scaled training data\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# Calculate a baseline r-squared score on training data\n",
    "print('Baseline r_sqaured on training data: ', linreg.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Interactions\n",
    "\n",
    "Instead of adding all possible interaction terms, let's try a custom technique. We are only going to add the interaction terms that increase the $R^2$ score as much as possible. Specifically we are going to look for the 7 interaction terms that each cause the most increase in the coefficient of determination.\n",
    "\n",
    "### Find the Best Interactions\n",
    "\n",
    "Look at all the possible combinations of variables for interactions by adding interactions one by one to the baseline model. Create a data structure that stores the pair of columns used as well as the $R^2$ score for each combination.\n",
    "\n",
    "***Hint:*** We have imported the `combinations` function from `itertools` for you ([documentation here](https://docs.python.org/3/library/itertools.html#itertools.combinations)). Try applying this to the columns of `X_train` to find all of the possible pairs.\n",
    "\n",
    "Print the 7 interactions that result in the highest $R^2$ scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LotArea', 'OverallQual'),\n",
       " ('LotArea', 'OverallCond'),\n",
       " ('LotArea', 'TotalBsmtSF'),\n",
       " ('LotArea', '1stFlrSF'),\n",
       " ('LotArea', '2ndFlrSF'),\n",
       " ('LotArea', 'GrLivArea'),\n",
       " ('LotArea', 'TotRmsAbvGrd'),\n",
       " ('LotArea', 'GarageArea'),\n",
       " ('LotArea', 'Fireplaces'),\n",
       " ('OverallQual', 'OverallCond'),\n",
       " ('OverallQual', 'TotalBsmtSF'),\n",
       " ('OverallQual', '1stFlrSF'),\n",
       " ('OverallQual', '2ndFlrSF'),\n",
       " ('OverallQual', 'GrLivArea'),\n",
       " ('OverallQual', 'TotRmsAbvGrd'),\n",
       " ('OverallQual', 'GarageArea'),\n",
       " ('OverallQual', 'Fireplaces'),\n",
       " ('OverallCond', 'TotalBsmtSF'),\n",
       " ('OverallCond', '1stFlrSF'),\n",
       " ('OverallCond', '2ndFlrSF'),\n",
       " ('OverallCond', 'GrLivArea'),\n",
       " ('OverallCond', 'TotRmsAbvGrd'),\n",
       " ('OverallCond', 'GarageArea'),\n",
       " ('OverallCond', 'Fireplaces'),\n",
       " ('TotalBsmtSF', '1stFlrSF'),\n",
       " ('TotalBsmtSF', '2ndFlrSF'),\n",
       " ('TotalBsmtSF', 'GrLivArea'),\n",
       " ('TotalBsmtSF', 'TotRmsAbvGrd'),\n",
       " ('TotalBsmtSF', 'GarageArea'),\n",
       " ('TotalBsmtSF', 'Fireplaces'),\n",
       " ('1stFlrSF', '2ndFlrSF'),\n",
       " ('1stFlrSF', 'GrLivArea'),\n",
       " ('1stFlrSF', 'TotRmsAbvGrd'),\n",
       " ('1stFlrSF', 'GarageArea'),\n",
       " ('1stFlrSF', 'Fireplaces'),\n",
       " ('2ndFlrSF', 'GrLivArea'),\n",
       " ('2ndFlrSF', 'TotRmsAbvGrd'),\n",
       " ('2ndFlrSF', 'GarageArea'),\n",
       " ('2ndFlrSF', 'Fireplaces'),\n",
       " ('GrLivArea', 'TotRmsAbvGrd'),\n",
       " ('GrLivArea', 'GarageArea'),\n",
       " ('GrLivArea', 'Fireplaces'),\n",
       " ('TotRmsAbvGrd', 'GarageArea'),\n",
       " ('TotRmsAbvGrd', 'Fireplaces'),\n",
       " ('GarageArea', 'Fireplaces')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combos = list(combinations(X_train.columns, 2))\n",
    "combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 interaction terms:  [(('LotArea', '1stFlrSF'), 0.7211105666140568), (('LotArea', 'TotalBsmtSF'), 0.707164920705011), (('LotArea', 'GrLivArea'), 0.6690980823779028), (('LotArea', 'Fireplaces'), 0.6529699515652587), (('2ndFlrSF', 'TotRmsAbvGrd'), 0.6472994890405193), (('OverallCond', 'TotalBsmtSF'), 0.642901987923377), (('OverallQual', '2ndFlrSF'), 0.6422324294284367)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Set up data structure\n",
    "interactions = []\n",
    "\n",
    "# Find combinations of columns and loop over them\n",
    "combos = list(combinations(X_train.columns, 2))\n",
    "for (col1, col2) in combos:\n",
    "    # Make copies of X_train and X_test\n",
    "    X_train_copy = X_train.copy()\n",
    "    X_test_copy = X_test.copy()\n",
    "    \n",
    "    # Add interaction term to data\n",
    "    X_train_copy['interaction'] = X_train_copy[col1] * X_train_copy[col2]\n",
    "    X_test_copy['interaction'] = X_test_copy[col1] * X_test_copy[col2]\n",
    "    \n",
    "    # Find r-squared score (fit on training data, evaluate on test data)\n",
    "    r2score = LinearRegression().fit(X_train_copy, y_train).score(X_test_copy, y_test)\n",
    "    \n",
    "    # Append to data structure\n",
    "    interactions.append(((col1, col2), r2score))\n",
    "    \n",
    "# Sort and subset the data structure to find the top 7\n",
    "top_interactions = sorted(interactions, key=lambda record: record[1], reverse=True)[:7]\n",
    "print(\"Top 7 interaction terms: \", top_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LotArea'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col1,col2 = top_interactions[0][0]\n",
    "col1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the Best Interactions\n",
    "\n",
    "Write code to include the 7 most important interactions in `X_train` and `X_test` by adding 7 columns. Use the naming convention `\"col1_col2\"`, where `col1` and `col2` are the two columns in the interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>LotArea_1stFlrSF</th>\n",
       "      <th>LotArea_TotalBsmtSF</th>\n",
       "      <th>LotArea_GrLivArea</th>\n",
       "      <th>LotArea_Fireplaces</th>\n",
       "      <th>2ndFlrSF_TotRmsAbvGrd</th>\n",
       "      <th>OverallCond_TotalBsmtSF</th>\n",
       "      <th>OverallQual_2ndFlrSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>-0.114710</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>-0.639316</td>\n",
       "      <td>-0.804789</td>\n",
       "      <td>1.261552</td>\n",
       "      <td>0.499114</td>\n",
       "      <td>0.250689</td>\n",
       "      <td>0.327629</td>\n",
       "      <td>-0.994820</td>\n",
       "      <td>0.092318</td>\n",
       "      <td>0.073336</td>\n",
       "      <td>-0.057254</td>\n",
       "      <td>0.114116</td>\n",
       "      <td>0.316257</td>\n",
       "      <td>0.325573</td>\n",
       "      <td>-0.125956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>-0.176719</td>\n",
       "      <td>0.632038</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>0.838208</td>\n",
       "      <td>0.641608</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.247249</td>\n",
       "      <td>-0.365525</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>-0.994820</td>\n",
       "      <td>-0.113385</td>\n",
       "      <td>-0.148128</td>\n",
       "      <td>0.043694</td>\n",
       "      <td>0.175804</td>\n",
       "      <td>0.295392</td>\n",
       "      <td>-0.426859</td>\n",
       "      <td>-0.510770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.246336</td>\n",
       "      <td>-0.831723</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-0.012560</td>\n",
       "      <td>-0.329000</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.944766</td>\n",
       "      <td>-0.981739</td>\n",
       "      <td>-1.105931</td>\n",
       "      <td>-0.994820</td>\n",
       "      <td>0.081045</td>\n",
       "      <td>0.003094</td>\n",
       "      <td>0.232730</td>\n",
       "      <td>0.245060</td>\n",
       "      <td>0.793375</td>\n",
       "      <td>-0.016386</td>\n",
       "      <td>0.672141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>-0.378617</td>\n",
       "      <td>-0.831723</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-0.339045</td>\n",
       "      <td>-0.609036</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-1.146010</td>\n",
       "      <td>-0.981739</td>\n",
       "      <td>-1.134602</td>\n",
       "      <td>0.588023</td>\n",
       "      <td>0.230591</td>\n",
       "      <td>0.128368</td>\n",
       "      <td>0.433899</td>\n",
       "      <td>-0.222636</td>\n",
       "      <td>0.793375</td>\n",
       "      <td>-0.442323</td>\n",
       "      <td>0.672141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>-0.010898</td>\n",
       "      <td>-1.563603</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-2.531499</td>\n",
       "      <td>-1.315922</td>\n",
       "      <td>0.550523</td>\n",
       "      <td>-0.481708</td>\n",
       "      <td>0.250689</td>\n",
       "      <td>-2.281450</td>\n",
       "      <td>-0.994820</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.027589</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.138010</td>\n",
       "      <td>-3.302627</td>\n",
       "      <td>-0.860799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       LotArea  OverallQual  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  \\\n",
       "518  -0.114710    -0.099842    -0.509252    -0.639316 -0.804789  1.261552   \n",
       "236  -0.176719     0.632038    -0.509252     0.838208  0.641608 -0.808132   \n",
       "38   -0.246336    -0.831723     1.304613    -0.012560 -0.329000 -0.808132   \n",
       "1034 -0.378617    -0.831723     1.304613    -0.339045 -0.609036 -0.808132   \n",
       "520  -0.010898    -1.563603     1.304613    -2.531499 -1.315922  0.550523   \n",
       "\n",
       "      GrLivArea  TotRmsAbvGrd  GarageArea  Fireplaces  LotArea_1stFlrSF  \\\n",
       "518    0.499114      0.250689    0.327629   -0.994820          0.092318   \n",
       "236   -0.247249     -0.365525    0.079146   -0.994820         -0.113385   \n",
       "38    -0.944766     -0.981739   -1.105931   -0.994820          0.081045   \n",
       "1034  -1.146010     -0.981739   -1.134602    0.588023          0.230591   \n",
       "520   -0.481708      0.250689   -2.281450   -0.994820          0.014341   \n",
       "\n",
       "      LotArea_TotalBsmtSF  LotArea_GrLivArea  LotArea_Fireplaces  \\\n",
       "518              0.073336          -0.057254            0.114116   \n",
       "236             -0.148128           0.043694            0.175804   \n",
       "38               0.003094           0.232730            0.245060   \n",
       "1034             0.128368           0.433899           -0.222636   \n",
       "520              0.027589           0.005250            0.010842   \n",
       "\n",
       "      2ndFlrSF_TotRmsAbvGrd  OverallCond_TotalBsmtSF  OverallQual_2ndFlrSF  \n",
       "518                0.316257                 0.325573             -0.125956  \n",
       "236                0.295392                -0.426859             -0.510770  \n",
       "38                 0.793375                -0.016386              0.672141  \n",
       "1034               0.793375                -0.442323              0.672141  \n",
       "520                0.138010                -3.302627             -0.860799  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Loop over top 7 interactions\n",
    "for entry in top_interactions:\n",
    "    # Extract column names from data structure\n",
    "    col1, col2 = entry[0]\n",
    "    \n",
    "    # Construct new column name\n",
    "    new_col = col1 + \"_\" + col2\n",
    "    \n",
    "    # Add new column to X_train and X_test\n",
    "    X_train[new_col] = X_train[col1] * X_train[col2]\n",
    "    X_test[new_col] = X_test[col1] * X_test[col2]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Polynomials\n",
    "\n",
    "Now let's repeat that process for adding polynomial terms.\n",
    "\n",
    "### Find the Best Polynomials\n",
    "\n",
    "Try polynomials of degrees 2, 3, and 4 for each variable, in a similar way you did for interactions (by looking at your baseline model and seeing how $R^2$ increases). Do understand that when going for a polynomial of degree 4 with `PolynomialFeatures`, the particular column is raised to the power of 2 and 3 as well in other terms.\n",
    "\n",
    "We only want to include \"pure\" polynomials, so make sure no interactions are included.\n",
    "\n",
    "Once again you should make a data structure that contains the values you have tested. We recommend a list of tuples of the form:\n",
    "\n",
    "`(col_name, degree, R2)`, so eg. `('OverallQual', 2, 0.781)` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 7 polynomials:  [('GrLivArea', 3, 0.8279572328370799), ('OverallQual_2ndFlrSF', 3, 0.8211851069980076), ('LotArea_Fireplaces', 4, 0.8116894230803908), ('LotArea_Fireplaces', 3, 0.811442481720325), ('OverallQual', 3, 0.805263042544518), ('OverallQual_2ndFlrSF', 2, 0.8050421284732353), ('OverallQual', 4, 0.8021678243265244)]\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Set up data structure\n",
    "polynomials = []\n",
    "# Loop over all columns\n",
    "for col in X_train.columns:\n",
    "    # Loop over degrees 2, 3, 4\n",
    "        for degree in (2, 3, 4):\n",
    "        # Make a copy of X_train and X_test\n",
    "            X_train_copy = X_train.copy().reset_index()\n",
    "            X_test_copy = X_test.copy().reset_index()\n",
    "            \n",
    "        # Instantiate PolynomialFeatures with relevant degree\n",
    "            poly = PolynomialFeatures(degree, include_bias=False)\n",
    "            \n",
    "        # Fit polynomial to column and transform column\n",
    "        # Hint: use the notation df[[column_name]] to get the right shape\n",
    "        # Hint: convert the result to a DataFrame\n",
    "            transformed_col_train = pd.DataFrame(poly.fit_transform(X_train_copy[[col]]))\n",
    "            transformed_col_test = pd.DataFrame(poly.transform(X_test_copy[[col]]))\n",
    "            \n",
    "        # Add polynomial to data\n",
    "        # Hint: use pd.concat since you're combining two DataFrames\n",
    "        # Hint: drop the column before combining so it doesn't appear twice\n",
    "            X_train_copy = pd.concat([X_train_copy.drop(col, axis=1), transformed_col_train], axis=1)\n",
    "            X_test_copy = pd.concat([X_test_copy.drop(col, axis=1), transformed_col_test], axis=1)\n",
    "            \n",
    "        # Find r-squared score\n",
    "            rsquared = LinearRegression().fit(X_train_copy, y_train).score(X_test_copy, y_test)\n",
    "        # Append to data structure\n",
    "            polynomials.append((col, degree, rsquared))\n",
    "            \n",
    "# Sort and subset the data structure to find the top 7\n",
    "top_polynomials = sorted(polynomials, key=lambda record: record[2], reverse=True)[:7]\n",
    "print(\"Top 7 polynomials: \", top_polynomials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the Best Polynomials\n",
    "\n",
    "If there are duplicate column values in the results above, don't add multiple of them to the model, to avoid creating duplicate columns. (For example, if column `A` appeared in your list as both a 2nd and 3rd degree polynomial, adding both would result in `A` squared being added to the features twice.) Just add in the polynomial that results in the highest R-Squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Col</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Rsquared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GrLivArea</td>\n",
       "      <td>3</td>\n",
       "      <td>0.827957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OverallQual_2ndFlrSF</td>\n",
       "      <td>3</td>\n",
       "      <td>0.821185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LotArea_Fireplaces</td>\n",
       "      <td>4</td>\n",
       "      <td>0.811689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OverallQual</td>\n",
       "      <td>3</td>\n",
       "      <td>0.805263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Col  Degree  Rsquared\n",
       "0             GrLivArea       3  0.827957\n",
       "1  OverallQual_2ndFlrSF       3  0.821185\n",
       "2    LotArea_Fireplaces       4  0.811689\n",
       "4           OverallQual       3  0.805263"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# Filter out duplicates\n",
    "top_polynomials = pd.DataFrame(top_polynomials, columns=['Col','Degree','Rsquared'])\n",
    "top_polynomials.drop_duplicates(subset='Col', inplace=True)\n",
    "top_polynomials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-4a46d838d862>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m# Create polynomial terms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpoly\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_bias\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     col_transformed_train = pd.DataFrame(poly.fit_transform(X_train[[col]]),\n\u001b[0m\u001b[0;32m      6\u001b[0m                                         columns=poly.get_feature_names([col]))\n\u001b[0;32m      7\u001b[0m     col_transformed_test = pd.DataFrame(poly.transform(X_test[[col]]),\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    688\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1510\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0minstance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1511\u001b[0m         \"\"\"\n\u001b[1;32m-> 1512\u001b[1;33m         n_samples, n_features = self._validate_data(\n\u001b[0m\u001b[0;32m   1513\u001b[0m             X, accept_sparse=True).shape\n\u001b[0;32m   1514\u001b[0m         combinations = self._combinations(n_features, self.degree,\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    418\u001b[0m                     \u001b[1;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m                 )\n\u001b[1;32m--> 420\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Loop over remaining results\n",
    "for (col, degree, _) in top_polynomials.values:\n",
    "    # Create polynomial terms\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    col_transformed_train = pd.DataFrame(poly.fit_transform(X_train[[col]]),\n",
    "                                        columns=poly.get_feature_names([col]))\n",
    "    col_transformed_test = pd.DataFrame(poly.transform(X_test[[col]]),\n",
    "                                    columns=poly.get_feature_names([col]))\n",
    "    # Concat new polynomials to X_train and X_test\n",
    "    X_train = pd.concat([X_train.drop(col, axis=1), col_transformed_train], axis=1)\n",
    "    X_test = pd.concat([X_test.drop(col, axis=1), col_transformed_test], axis=1)\n",
    "    \n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out your final data set and make sure that your interaction terms as well as your polynomial terms are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full Model R-Squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the $R^2$ of the full model with your interaction and polynomial terms added. Print this value for both the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "print('Rsquared Training: ', linreg.score(X_train, y_train))\n",
    "print('Rsquared Test: ', linreg.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we may be overfitting some now. Let's try some feature selection techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "First, test out `RFE` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFE.html)) with several different `n_features_to_select` values. For each value, print out the train and test $R^2$ score and how many features remain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for n in [5, 10, 15, 20, 25]:\n",
    "    rfe = RFE(LinearRegression(), n_features_to_select=n)\n",
    "    X_rfe_train = rfe.fit_transform(X_train, y_train)\n",
    "    X_rfe_test = rfe.transform(X_test)\n",
    "    \n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_rfe_train, y_train)\n",
    "    \n",
    "    print('Rsquared Training: ', linreg.score(X_rfe_train, y_train))\n",
    "    print('Rsquared Test: ', linreg.score(X_rfe_test, y_test))\n",
    "    print(f'Using {n} out of {X_train.shape[1]} features')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test out `Lasso` ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)) with several different `alpha` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "for alpha in [1, 10, 100, 1000, 10000]:\n",
    "    lasso = Lasso(alpha=alpha)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    \n",
    "    print('Rsquared Training: ', lasso.score(X_train, y_train))\n",
    "    print('Rsquared Test: ', lasso.score(X_test, y_test))\n",
    "    print(f\"Using {sum(abs(lasso.coef_) < 10**(-10))} out of {X_train.shape[1]} features\")\n",
    "    print(\"and an alpha of\", alpha)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results. Which features would you choose to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your written answer here\n",
    "\"\"\"\n",
    "For RFE the model with the best test R-Squared was using 20 features\n",
    "\n",
    "For Lasso the model with the best test R-Squared was using an alpha of 10000\n",
    "\n",
    "The Lasso result was a bit better so let's go with that and the 14 features\n",
    "that it selected\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Final Model on Validation Data\n",
    "\n",
    "### Data Preparation\n",
    "\n",
    "At the start of this lab, we created `X_val` and `y_val`. Prepare `X_val` the same way that `X_train` and `X_test` have been prepared. This includes scaling, adding interactions, and adding polynomial terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 26 features, but this StandardScaler is expecting 10 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-729b412b7cef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# Scale X_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX_val_scaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 791\u001b[1;33m         X = self._validate_data(X, reset=False,\n\u001b[0m\u001b[0;32m    792\u001b[0m                                 \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    793\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ensure_2d'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    375\u001b[0m                 )\n\u001b[0;32m    376\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    378\u001b[0m                     \u001b[1;34m'X has {} features, but this {} is expecting {} features '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m                     'as input.'.format(n_features, self.__class__.__name__,\n",
      "\u001b[1;31mValueError\u001b[0m: X has 26 features, but this StandardScaler is expecting 10 features as input."
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "# Scale X_val\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_val = pd.DataFrame(X_val_scaled, columns=X.columns)\n",
    "\n",
    "# Add interactions to X_val\n",
    "for record in top_interactions:\n",
    "    col1, col2 = record[0]\n",
    "    new_col_name = col1 + \"_\" + col2\n",
    "    X_val[new_col_name] = X_val[col1] * X_val[col2]\n",
    "\n",
    "# Add polynomials to X_val\n",
    "for (col, degree, _) in top_polynomials.values:\n",
    "    poly = PolynomialFeatures(degree, include_bias=False)\n",
    "    col_transformed_val = pd.DataFrame(poly.fit_transform(X_val[[col]]),\n",
    "                                        columns=poly.get_feature_names([col]))\n",
    "    X_val = pd.concat([X_val.drop(col, axis=1), col_transformed_val], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>LotArea_1stFlrSF</th>\n",
       "      <th>LotArea_TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>OverallQual_2ndFlrSF</th>\n",
       "      <th>OverallQual_2ndFlrSF^2</th>\n",
       "      <th>OverallQual_2ndFlrSF^3</th>\n",
       "      <th>LotArea_Fireplaces</th>\n",
       "      <th>LotArea_Fireplaces^2</th>\n",
       "      <th>LotArea_Fireplaces^3</th>\n",
       "      <th>LotArea_Fireplaces^4</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallQual^2</th>\n",
       "      <th>OverallQual^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.206088</td>\n",
       "      <td>2.211546</td>\n",
       "      <td>-0.007794</td>\n",
       "      <td>-0.299094</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.365525</td>\n",
       "      <td>-1.019917</td>\n",
       "      <td>-0.994820</td>\n",
       "      <td>0.061640</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080686</td>\n",
       "      <td>0.006510</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.205020</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>-0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108211</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>0.954980</td>\n",
       "      <td>0.875424</td>\n",
       "      <td>1.732552</td>\n",
       "      <td>1.483117</td>\n",
       "      <td>1.120866</td>\n",
       "      <td>2.170867</td>\n",
       "      <td>0.094731</td>\n",
       "      <td>0.103340</td>\n",
       "      <td>...</td>\n",
       "      <td>2.363059</td>\n",
       "      <td>5.584046</td>\n",
       "      <td>13.195427</td>\n",
       "      <td>0.234913</td>\n",
       "      <td>0.055184</td>\n",
       "      <td>0.012963</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>1.363918</td>\n",
       "      <td>1.860273</td>\n",
       "      <td>2.537259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.161422</td>\n",
       "      <td>0.397681</td>\n",
       "      <td>-0.129332</td>\n",
       "      <td>-0.407845</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.981739</td>\n",
       "      <td>-0.561178</td>\n",
       "      <td>0.588023</td>\n",
       "      <td>0.065835</td>\n",
       "      <td>0.020877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.672141</td>\n",
       "      <td>0.451774</td>\n",
       "      <td>0.303656</td>\n",
       "      <td>-0.094920</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-0.831723</td>\n",
       "      <td>0.691762</td>\n",
       "      <td>-0.575354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.485374</td>\n",
       "      <td>1.304613</td>\n",
       "      <td>-0.138864</td>\n",
       "      <td>-0.473096</td>\n",
       "      <td>0.686388</td>\n",
       "      <td>0.250689</td>\n",
       "      <td>-0.274466</td>\n",
       "      <td>2.170867</td>\n",
       "      <td>0.229629</td>\n",
       "      <td>0.067401</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.068531</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-1.053682</td>\n",
       "      <td>1.110247</td>\n",
       "      <td>-1.169847</td>\n",
       "      <td>1.232648</td>\n",
       "      <td>-0.099842</td>\n",
       "      <td>0.009968</td>\n",
       "      <td>-0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.160731</td>\n",
       "      <td>-0.509252</td>\n",
       "      <td>1.329127</td>\n",
       "      <td>1.201679</td>\n",
       "      <td>-0.808132</td>\n",
       "      <td>-0.365525</td>\n",
       "      <td>2.076573</td>\n",
       "      <td>0.588023</td>\n",
       "      <td>0.193147</td>\n",
       "      <td>0.213632</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.693681</td>\n",
       "      <td>2.868556</td>\n",
       "      <td>-4.858419</td>\n",
       "      <td>0.094514</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>2.095798</td>\n",
       "      <td>4.392371</td>\n",
       "      <td>9.205523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    LotArea  OverallCond  TotalBsmtSF  1stFlrSF  2ndFlrSF  TotRmsAbvGrd  \\\n",
       "0 -0.206088     2.211546    -0.007794 -0.299094 -0.808132     -0.365525   \n",
       "1  0.108211    -0.509252     0.954980  0.875424  1.732552      1.483117   \n",
       "2 -0.161422     0.397681    -0.129332 -0.407845 -0.808132     -0.981739   \n",
       "3 -0.485374     1.304613    -0.138864 -0.473096  0.686388      0.250689   \n",
       "4  0.160731    -0.509252     1.329127  1.201679 -0.808132     -0.365525   \n",
       "\n",
       "   GarageArea  Fireplaces  LotArea_1stFlrSF  LotArea_TotalBsmtSF  ...  \\\n",
       "0   -1.019917   -0.994820          0.061640             0.001606  ...   \n",
       "1    1.120866    2.170867          0.094731             0.103340  ...   \n",
       "2   -0.561178    0.588023          0.065835             0.020877  ...   \n",
       "3   -0.274466    2.170867          0.229629             0.067401  ...   \n",
       "4    2.076573    0.588023          0.193147             0.213632  ...   \n",
       "\n",
       "   OverallQual_2ndFlrSF  OverallQual_2ndFlrSF^2  OverallQual_2ndFlrSF^3  \\\n",
       "0              0.080686                0.006510                0.000525   \n",
       "1              2.363059                5.584046               13.195427   \n",
       "2              0.672141                0.451774                0.303656   \n",
       "3             -0.068531                0.004696               -0.000322   \n",
       "4             -1.693681                2.868556               -4.858419   \n",
       "\n",
       "   LotArea_Fireplaces  LotArea_Fireplaces^2  LotArea_Fireplaces^3  \\\n",
       "0            0.205020              0.042033              0.008618   \n",
       "1            0.234913              0.055184              0.012963   \n",
       "2           -0.094920              0.009010             -0.000855   \n",
       "3           -1.053682              1.110247             -1.169847   \n",
       "4            0.094514              0.008933              0.000844   \n",
       "\n",
       "   LotArea_Fireplaces^4  OverallQual  OverallQual^2  OverallQual^3  \n",
       "0              0.001767    -0.099842       0.009968      -0.000995  \n",
       "1              0.003045     1.363918       1.860273       2.537259  \n",
       "2              0.000081    -0.831723       0.691762      -0.575354  \n",
       "3              1.232648    -0.099842       0.009968      -0.000995  \n",
       "4              0.000080     2.095798       4.392371       9.205523  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using either `RFE` or `Lasso`, fit a model on the complete train + test set, then find R-Squared and MSE values for the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-92b3cbef07eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Your code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfinal_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"R-Squared:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    757\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[0mX_copied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m             X, y = self._validate_data(X, y, accept_sparse='csc',\n\u001b[0m\u001b[0;32m    760\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'F'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m                                        \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             _assert_all_finite(array,\n\u001b[0m\u001b[0;32m    645\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\learn-env\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     94\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     95\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m     97\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m                     (type_err,\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "final_model = Lasso(alpha=10000)\n",
    "final_model.fit(pd.concat([X_train, X_test]), pd.concat([y_train, y_test]))\n",
    "\n",
    "print(\"R-Squared:\", final_model.score(X_val, y_val))\n",
    "print(\"MSE:\", mean_squared_error(y_val, final_model.predict(X_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up Ideas (Optional)\n",
    "\n",
    "### Create a Lasso Path\n",
    "\n",
    "From this section, you know that when using `Lasso`, more parameters shrink to zero as your regularization parameter goes up. In scikit-learn there is a function `lasso_path()` which visualizes the shrinkage of the coefficients while $alpha$ changes. Try this out yourself!\n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/linear_model/plot_lasso_coordinate_descent_path.html#sphx-glr-auto-examples-linear-model-plot-lasso-coordinate-descent-path-py\n",
    "\n",
    "### AIC and BIC for Subset Selection\n",
    "\n",
    "This notebook shows how you can use AIC and BIC purely for feature selection. Try this code out on our Ames housing data!\n",
    "\n",
    "https://xavierbourretsicotte.github.io/subset_selection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You now know how to apply concepts of bias-variance tradeoff using extensions to linear models and feature selection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
